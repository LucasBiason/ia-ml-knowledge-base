{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tutorial 03: Par√¢metros Avan√ßados da API\n",
        "\n",
        "**Objetivos de Aprendizagem:**\n",
        "- Dominar todos os par√¢metros da API de Chat Completions\n",
        "- Entender quando e como usar cada par√¢metro\n",
        "- Otimizar respostas para diferentes casos de uso\n",
        "- Controlar custos e qualidade das respostas\n",
        "\n",
        "**Pr√©-requisitos:**\n",
        "- Tutorial 01: Conversa B√°sica conclu√≠do\n",
        "- Compreens√£o b√°sica de requisi√ß√µes √† API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introdu√ß√£o\n",
        "\n",
        "A API de Chat Completions oferece diversos par√¢metros que permitem controlar o comportamento, qualidade e custo das respostas. Dominar esses par√¢metros √© essencial para criar aplica√ß√µes eficientes e de alta qualidade.\n",
        "\n",
        "### Par√¢metros que Vamos Explorar\n",
        "\n",
        "1. **temperature** - Controla criatividade e aleatoriedade\n",
        "2. **max_tokens** - Limita tamanho da resposta\n",
        "3. **top_p** - Nucleus sampling (diversidade)\n",
        "4. **frequency_penalty** - Reduz repeti√ß√£o de palavras\n",
        "5. **presence_penalty** - Incentiva novos t√≥picos\n",
        "6. **n** - N√∫mero de respostas geradas\n",
        "7. **stop** - Sequ√™ncias que param a gera√ß√£o\n",
        "\n",
        "## Importante: Combinando Par√¢metros\n",
        "\n",
        "Os par√¢metros podem ser combinados para obter resultados espec√≠ficos. Por exemplo:\n",
        "- `temperature=0.7` + `top_p=0.9` = Respostas criativas e diversas\n",
        "- `temperature=0.2` + `frequency_penalty=0.5` = Respostas precisas sem repeti√ß√£o\n",
        "- `max_tokens=200` + `presence_penalty=0.6` = Respostas curtas e variadas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cliente OpenAI configurado!\n"
          ]
        }
      ],
      "source": [
        "# Configura√ß√£o inicial\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "\n",
        "load_dotenv()\n",
        "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
        "\n",
        "print(\"Cliente OpenAI configurado!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Par√¢metro 1: temperature\n",
        "\n",
        "Controla a aleatoriedade e criatividade das respostas.\n",
        "\n",
        "**Valores:**\n",
        "- **0.0**: Determin√≠stico, sempre a mesma resposta (√∫til para tarefas que precisam de consist√™ncia)\n",
        "- **0.2-0.5**: Baixa criatividade, respostas mais diretas e precisas\n",
        "- **0.7**: Equil√≠brio entre criatividade e precis√£o (padr√£o recomendado)\n",
        "- **1.0-1.5**: Alta criatividade, respostas variadas e elaboradas\n",
        "- **2.0**: M√°xima criatividade (pode gerar respostas muito diferentes)\n",
        "\n",
        "**Quando usar:**\n",
        "- **Baixa (0.0-0.3)**: An√°lise de dados, extra√ß√£o de informa√ß√µes, tarefas t√©cnicas\n",
        "- **M√©dia (0.7)**: Conversas gerais, assistentes, maioria dos casos\n",
        "- **Alta (1.0+)**: Gera√ß√£o criativa, brainstorming, escrita criativa\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Temperature 0.2 (Baixa) ===\n",
            "Python √© uma linguagem de programa√ß√£o de alto n√≠vel, interpretada e de f√°cil aprendizado.\n",
            "\n",
            "=== Temperature 1.5 (Alta) ===\n",
            "Python √© como uma serpente charmosa que mora no mundo da programa√ß√£o. Esta serpente pitoresca desliza suavemente entre as linhas de c√≥digo, envolvendo funcionamentos misteriosos e processos l√≥gicos. Com seu veneno certeiro, Python √© capaz de resolver os problemas mais complexos de forma eficiente e elegante. Al√©m disso, √© uma serpente acolhedora, sempre pronta para receber novos programadores em seu territ√≥rio, incentivando-os a explorar suas vastas habilidades e possibilidades. Em resumo, Python √© uma peculiar serpente programadora que encanta e conquista a todos que se aventuram por seus caminhos. üêçüíª\n"
          ]
        }
      ],
      "source": [
        "# Exemplo com temperature baixa (respostas mais determin√≠sticas)\n",
        "response = client.chat.completions.create(\n",
        "    model='gpt-3.5-turbo',\n",
        "    messages=[\n",
        "        {\n",
        "            'role': 'user',\n",
        "            'content': 'Explique o que √© Python em uma frase.'\n",
        "        }\n",
        "    ],\n",
        "    temperature=0.2  # Baixa criatividade, resposta mais direta\n",
        ")\n",
        "\n",
        "print(\"=== Temperature 0.2 (Baixa) ===\")\n",
        "print(response.choices[0].message.content)\n",
        "print()\n",
        "\n",
        "# Exemplo com temperature alta (respostas mais criativas)\n",
        "response = client.chat.completions.create(\n",
        "    model='gpt-3.5-turbo',\n",
        "    messages=[\n",
        "        {\n",
        "            'role': 'user',\n",
        "            'content': 'Explique o que √© Python de forma criativa.'\n",
        "        }\n",
        "    ],\n",
        "    temperature=1.5  # Alta criatividade, resposta mais elaborada\n",
        ")\n",
        "\n",
        "print(\"=== Temperature 1.5 (Alta) ===\")\n",
        "print(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Par√¢metro 2: max_tokens\n",
        "\n",
        "Limita o n√∫mero m√°ximo de tokens na resposta. √ötil para controlar custos e tamanho da resposta.\n",
        "\n",
        "**Considera√ß√µes:**\n",
        "- Tokens s√£o unidades de texto (aproximadamente 4 caracteres = 1 token)\n",
        "- Respostas s√£o cortadas se excederem o limite\n",
        "- N√£o inclui tokens do prompt, apenas da resposta\n",
        "- Padr√£o: determinado pelo modelo (geralmente muito alto)\n",
        "\n",
        "**Quando usar:**\n",
        "- **50-100 tokens**: Respostas muito curtas, t√≠tulos, tags\n",
        "- **200-500 tokens**: Respostas m√©dias, par√°grafos\n",
        "- **1000+ tokens**: Respostas longas, artigos, an√°lises detalhadas\n",
        "\n",
        "**Dica:** Use `max_tokens` para controlar custos em produ√ß√£o!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Max Tokens 50 (Resposta Curta) ===\n",
            "Machine Learning √© uma subcategoria da intelig√™ncia artificial que envolve o desenvolvimento de algoritmos e modelos que permitem que os sistemas computacionais analisem dados, identifiquem padr√µes e fa√ßam previs√µes sem ser\n",
            "Tokens usados: 50\n",
            "\n",
            "=== Max Tokens 500 (Resposta Longa) ===\n",
            "Machine Learning √© uma t√©cnica de intelig√™ncia artificial que permite aos computadores aprenderem e melhorarem suas habilidades sem serem explicitamente programados. Em vez disso, os computadores s√£o capazes de reconhecer padr√µes e tomar decis√µes com base nos dados dispon√≠veis. Isso √© feito atrav√©s de algoritmos que analisam grandes conjuntos de dados e identificam rela√ß√µes e tend√™ncias para fazer previs√µes ou tomar decis√µes. O Machine Learning √© amplamente utilizado em diversas √°reas, como reconhecimento de fala, vis√£o computacional, recomenda√ß√£o de produtos, detec√ß√£o de fraudes, entre outros. √â uma tecnologia poderosa que vem sendo cada vez mais adotada por empresas para melhorar seus processos e oferecer melhores servi√ßos aos clientes.\n",
            "Tokens usados: 168\n"
          ]
        }
      ],
      "source": [
        "# Resposta curta (50 tokens)\n",
        "response = client.chat.completions.create(\n",
        "    model='gpt-3.5-turbo',\n",
        "    messages=[\n",
        "        {\n",
        "            'role': 'user',\n",
        "            'content': 'Explique o que √© Machine Learning.'\n",
        "        }\n",
        "    ],\n",
        "    max_tokens=50  # Limita a resposta a 50 tokens\n",
        ")\n",
        "\n",
        "print(\"=== Max Tokens 50 (Resposta Curta) ===\")\n",
        "print(response.choices[0].message.content)\n",
        "print(f\"Tokens usados: {response.usage.completion_tokens}\")\n",
        "print()\n",
        "\n",
        "# Resposta longa (500 tokens)\n",
        "response = client.chat.completions.create(\n",
        "    model='gpt-3.5-turbo',\n",
        "    messages=[\n",
        "        {\n",
        "            'role': 'user',\n",
        "            'content': 'Explique o que √© Machine Learning.'\n",
        "        }\n",
        "    ],\n",
        "    max_tokens=500  # Permite resposta mais longa\n",
        ")\n",
        "\n",
        "print(\"=== Max Tokens 500 (Resposta Longa) ===\")\n",
        "print(response.choices[0].message.content)\n",
        "print(f\"Tokens usados: {response.usage.completion_tokens}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Par√¢metro 3: top_p (Nucleus Sampling)\n",
        "\n",
        "Controla a diversidade considerando apenas tokens com probabilidade acumulada.\n",
        "\n",
        "**Como funciona:**\n",
        "- O modelo considera apenas os tokens mais prov√°veis at√© atingir a probabilidade acumulada especificada\n",
        "- `top_p=0.1` = Considera apenas top 10% mais prov√°veis (muito focado)\n",
        "- `top_p=0.9` = Considera top 90% mais prov√°veis (mais diverso)\n",
        "- `top_p=1.0` = Considera todos os tokens\n",
        "\n",
        "**Quando usar:**\n",
        "- **Baixo (0.1-0.3)**: Respostas focadas, precisas\n",
        "- **M√©dio (0.5-0.7)**: Equil√≠brio entre foco e diversidade\n",
        "- **Alto (0.9-1.0)**: Respostas mais diversas, criativas\n",
        "\n",
        "**Nota:** `top_p` e `temperature` podem ser usados juntos, mas geralmente voc√™ escolhe um ou outro.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Top P 0.9 (Diverso) ===\n",
            "1. TecnoVanguarda\n",
            "2. InovaTech Solutions\n",
            "3. FuturisTech Group\n"
          ]
        }
      ],
      "source": [
        "# Exemplo com top_p para diversidade\n",
        "response = client.chat.completions.create(\n",
        "    model='gpt-3.5-turbo',\n",
        "    messages=[\n",
        "        {\n",
        "            'role': 'user',\n",
        "            'content': 'D√™ 3 ideias de nomes para uma startup de tecnologia.'\n",
        "        }\n",
        "    ],\n",
        "    top_p=0.9  # Mais diversidade nas respostas\n",
        ")\n",
        "\n",
        "print(\"=== Top P 0.9 (Diverso) ===\")\n",
        "print(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Par√¢metro 4: frequency_penalty\n",
        "\n",
        "Penaliza tokens que aparecem com frequ√™ncia no texto, reduzindo repeti√ß√£o.\n",
        "\n",
        "**Valores:**\n",
        "- **Negativos (-2.0 a 0.0)**: Incentiva repeti√ß√£o (raramente usado)\n",
        "- **0.0**: Sem penalidade (padr√£o)\n",
        "- **Positivos (0.1 a 2.0)**: Reduz repeti√ß√£o de palavras\n",
        "\n",
        "**Quando usar:**\n",
        "- **0.0**: Quando repeti√ß√£o n√£o √© problema\n",
        "- **0.3-0.7**: Para evitar repeti√ß√£o moderada\n",
        "- **1.0+**: Para evitar repeti√ß√£o excessiva (pode afetar qualidade)\n",
        "\n",
        "**Caso de uso:** Gera√ß√£o de listas, par√°grafos longos, conte√∫do onde repeti√ß√£o √© indesejada.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Frequency Penalty 0.5 (Reduz Repeti√ß√£o) ===\n",
            "Python √© uma linguagem de programa√ß√£o vers√°til e poderosa, que ganhou popularidade devido √† sua simplicidade e praticidade. Com uma grande comunidade de desenvolvedores ativos, oferece uma ampla gama de bibliotecas e frameworks para facilitar o desenvolvimento de projetos diversos. Sua sintaxe limpa e leg√≠vel torna a codifica√ß√£o mais intuitiva e eficiente, permitindo a cria√ß√£o de aplica√ß√µes robustas e escal√°veis. Al√©m disso, a portabilidade do Python o torna uma excelente escolha para a constru√ß√£o de aplicativos multiplataforma.\n"
          ]
        }
      ],
      "source": [
        "# Exemplo com frequency_penalty para reduzir repeti√ß√£o\n",
        "response = client.chat.completions.create(\n",
        "    model='gpt-3.5-turbo',\n",
        "    messages=[\n",
        "        {\n",
        "            'role': 'user',\n",
        "            'content': 'Escreva um par√°grafo sobre Python sem repetir palavras.'\n",
        "        }\n",
        "    ],\n",
        "    frequency_penalty=0.5  # Reduz repeti√ß√£o de palavras\n",
        ")\n",
        "\n",
        "print(\"=== Frequency Penalty 0.5 (Reduz Repeti√ß√£o) ===\")\n",
        "print(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Par√¢metro 5: presence_penalty\n",
        "\n",
        "Penaliza tokens baseado em se j√° apareceram no texto. Incentiva o modelo a falar sobre novos t√≥picos.\n",
        "\n",
        "**Valores:**\n",
        "- **Negativos (-2.0 a 0.0)**: Incentiva focar em t√≥picos j√° mencionados\n",
        "- **0.0**: Sem penalidade (padr√£o)\n",
        "- **Positivos (0.1 a 2.0)**: Incentiva diversidade de t√≥picos\n",
        "\n",
        "**Quando usar:**\n",
        "- **0.0**: Quando continuidade de t√≥pico √© desejada\n",
        "- **0.3-0.7**: Para brainstorming, listas diversas\n",
        "- **1.0+**: Para m√°xima diversidade de t√≥picos\n",
        "\n",
        "**Caso de uso:** Brainstorming, gera√ß√£o de ideias, listas com itens diversos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Presence Penalty 0.6 (Diversidade de T√≥picos) ===\n",
            "1. Pratique: A pr√°tica √© essencial para melhorar suas habilidades de programa√ß√£o em Python. Dedique tempo diariamente para resolver problemas e criar projetos utilizando a linguagem.\n",
            "\n",
            "2. Utilize recursos online: Existem diversos tutoriais, cursos e documenta√ß√µes dispon√≠veis na internet que podem te ajudar a aprender mais sobre Python. Utilize esses recursos para se aprofundar na linguagem.\n",
            "\n",
            "3. Participe da comunidade: Participe de f√≥runs de discuss√£o, grupos no LinkedIn, Reddit e outras redes sociais voltadas para desenvolvedores Python. Compartilhe experi√™ncias, tire d√∫vidas e aprenda com outros programadores.\n",
            "\n",
            "4. Escreva c√≥digo limpo: Mantenha seu c√≥digo organizado e leg√≠vel. Utilize boas pr√°ticas de programa√ß√£o, como nomes de vari√°veis claros, coment√°rios explicativos e indenta√ß√£o consistente.\n",
            "\n",
            "5. Explore bibliotecas e frameworks: Python possui uma vasta cole√ß√£o de bibliotecas e frameworks que podem facilitar o desenvolvimento de projetos. Explore as op√ß√µes dispon√≠veis e utilize-as para otimizar seu trabalho.\n"
          ]
        }
      ],
      "source": [
        "# Exemplo com presence_penalty para diversidade de t√≥picos\n",
        "response = client.chat.completions.create(\n",
        "    model='gpt-3.5-turbo',\n",
        "    messages=[\n",
        "        {\n",
        "            'role': 'user',\n",
        "            'content': 'D√™ 5 dicas diferentes sobre programa√ß√£o Python.'\n",
        "        }\n",
        "    ],\n",
        "    presence_penalty=0.6  # Incentiva diversidade de t√≥picos\n",
        ")\n",
        "\n",
        "print(\"=== Presence Penalty 0.6 (Diversidade de T√≥picos) ===\")\n",
        "print(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Par√¢metro 6: n (N√∫mero de Respostas)\n",
        "\n",
        "Gera m√∫ltiplas respostas para a mesma pergunta. √ötil para comparar diferentes abordagens.\n",
        "\n",
        "**Valores:**\n",
        "- **1**: Uma resposta (padr√£o, mais econ√¥mico)\n",
        "- **2-10**: M√∫ltiplas respostas (aumenta custo proporcionalmente)\n",
        "\n",
        "**Quando usar:**\n",
        "- **1**: Maioria dos casos (mais eficiente)\n",
        "- **2-3**: Quando voc√™ quer op√ß√µes para escolher\n",
        "- **5+**: Para an√°lise comparativa, A/B testing\n",
        "\n",
        "**Nota:** Cada resposta adicional custa o mesmo que uma requisi√ß√£o separada!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== N=3 (M√∫ltiplas Respostas) ===\n",
            "\n",
            "Resposta 1:\n",
            "Uma dica importante sobre Python √© sempre se atentar aos detalhes de indenta√ß√£o, pois o Python utiliza a indenta√ß√£o para determinar blocos de c√≥digo. Certifique-se de manter a consist√™ncia na indenta√ß√£o do seu c√≥digo para evitar erros de sintaxe.\n",
            "\n",
            "Resposta 2:\n",
            "Python √© uma linguagem de programa√ß√£o de alto n√≠vel, f√°cil de aprender e com uma sintaxe limpa e leg√≠vel. √â uma √≥tima escolha para iniciantes na programa√ß√£o, mas tamb√©m √© amplamente utilizada em desenvolvimento web, an√°lise de dados, intelig√™ncia artificial, entre outros. Vale a pena explorar a vasta biblioteca de fun√ß√µes e m√≥dulos dispon√≠veis na linguagem.\n",
            "\n",
            "Resposta 3:\n",
            "Python √© uma linguagem de programa√ß√£o de alto n√≠vel, conhecida por sua simplicidade e legibilidade. Uma dica importante √© sempre utilizar a indenta√ß√£o corretamente, pois ela √© fundamental para a estrutura do seu c√≥digo em Python. A indenta√ß√£o correta ajuda na organiza√ß√£o e legibilidade do c√≥digo, facilitando a identifica√ß√£o de blocos de c√≥digo e a compreens√£o do programa como um todo.\n"
          ]
        }
      ],
      "source": [
        "# Exemplo gerando m√∫ltiplas respostas\n",
        "response = client.chat.completions.create(\n",
        "    model='gpt-3.5-turbo',\n",
        "    messages=[\n",
        "        {\n",
        "            'role': 'user',\n",
        "            'content': 'D√™ uma dica sobre Python.'\n",
        "        }\n",
        "    ],\n",
        "    n=3  # Gera 3 respostas diferentes\n",
        ")\n",
        "\n",
        "print(\"=== N=3 (M√∫ltiplas Respostas) ===\")\n",
        "for i, choice in enumerate(response.choices, 1):\n",
        "    print(f\"\\nResposta {i}:\")\n",
        "    print(choice.message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Par√¢metro 7: stop\n",
        "\n",
        "Sequ√™ncias de texto que param a gera√ß√£o quando encontradas.\n",
        "\n",
        "**Formato:**\n",
        "- String √∫nica: `stop=\"FIM\"`\n",
        "- Lista de strings: `stop=[\"FIM\", \"FINAL\"]`\n",
        "\n",
        "**Quando usar:**\n",
        "- Para limitar respostas a um formato espec√≠fico\n",
        "- Para parar em marcadores espec√≠ficos\n",
        "- Para controlar estrutura de sa√≠da\n",
        "\n",
        "**Exemplo:** Se voc√™ quer que a resposta termine em \"---\", use `stop=\"---\"`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Com Stop Sequence ===\n",
            "Python \n"
          ]
        }
      ],
      "source": [
        "# Exemplo com stop para parar em marcador espec√≠fico\n",
        "response = client.chat.completions.create(\n",
        "    model='gpt-3.5-turbo',\n",
        "    messages=[\n",
        "        {\n",
        "            'role': 'user',\n",
        "            'content': 'Liste 5 linguagens de programa√ß√£o. Use \"---\" como separador entre cada uma.'\n",
        "        }\n",
        "    ],\n",
        "    stop=\"---\",  # Para quando encontrar \"---\"\n",
        "    max_tokens=200\n",
        ")\n",
        "\n",
        "print(\"=== Com Stop Sequence ===\")\n",
        "print(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Combinando Par√¢metros: Casos de Uso Pr√°ticos\n",
        "\n",
        "### Caso 1: Resposta T√©cnica Precisa\n",
        "```python\n",
        "temperature=0.2,\n",
        "max_tokens=300,\n",
        "frequency_penalty=0.3\n",
        "```\n",
        "**Uso:** Documenta√ß√£o t√©cnica, explica√ß√µes precisas\n",
        "\n",
        "### Caso 2: Gera√ß√£o Criativa\n",
        "```python\n",
        "temperature=1.2,\n",
        "top_p=0.9,\n",
        "presence_penalty=0.6\n",
        "```\n",
        "**Uso:** Brainstorming, escrita criativa, ideias\n",
        "\n",
        "### Caso 3: Resposta Curta e Eficiente\n",
        "```python\n",
        "max_tokens=100,\n",
        "temperature=0.7,\n",
        "stop=[\"\\n\\n\"]\n",
        "```\n",
        "**Uso:** Resumos, t√≠tulos, respostas r√°pidas\n",
        "\n",
        "### Caso 4: An√°lise Detalhada\n",
        "```python\n",
        "temperature=0.5,\n",
        "max_tokens=1000,\n",
        "frequency_penalty=0.4\n",
        "```\n",
        "**Uso:** An√°lises longas, relat√≥rios, artigos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resumo dos Par√¢metros\n",
        "\n",
        "| Par√¢metro | Tipo | Padr√£o | Range | Quando Usar |\n",
        "|-----------|------|--------|------|-------------|\n",
        "| `temperature` | float | 1.0 | 0.0-2.0 | Controlar criatividade |\n",
        "| `max_tokens` | int | Modelo | 1+ | Controlar custos/tamanho |\n",
        "| `top_p` | float | 1.0 | 0.0-1.0 | Controlar diversidade |\n",
        "| `frequency_penalty` | float | 0.0 | -2.0-2.0 | Reduzir repeti√ß√£o |\n",
        "| `presence_penalty` | float | 0.0 | -2.0-2.0 | Incentivar novos t√≥picos |\n",
        "| `n` | int | 1 | 1-10 | Gerar m√∫ltiplas respostas |\n",
        "| `stop` | str/list | None | - | Parar em sequ√™ncias espec√≠ficas |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exerc√≠cios Pr√°ticos\n",
        "\n",
        "### Exerc√≠cio 1: Otimizar para Tarefa Espec√≠fica\n",
        "Crie uma requisi√ß√£o otimizada para gerar t√≠tulos de artigos (curtos, criativos, sem repeti√ß√£o).\n",
        "\n",
        "### Exerc√≠cio 2: Comparar Configura√ß√µes\n",
        "Teste a mesma pergunta com diferentes combina√ß√µes de par√¢metros e compare os resultados.\n",
        "\n",
        "### Exerc√≠cio 3: Controlar Custos\n",
        "Use `max_tokens` para limitar respostas a 150 tokens e compare o custo antes e depois."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Refer√™ncias\n",
        "\n",
        "- [Documenta√ß√£o - Par√¢metros da API](https://platform.openai.com/docs/api-reference/chat/create)\n",
        "- [Guia de Prompt Engineering](https://platform.openai.com/docs/guides/prompt-engineering)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (IAMASTER venv)",
      "language": "python",
      "name": "iamaster-venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
