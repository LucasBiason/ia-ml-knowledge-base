{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 01: Conversa Básica com Chat Completions\n",
    "\n",
    "**Objetivos de Aprendizagem:**\n",
    "- Entender como fazer uma requisição básica à API de Chat Completions\n",
    "- Compreender os diferentes roles (system, user, assistant)\n",
    "- Aprender a configurar parâmetros básicos (model, temperature, max_tokens)\n",
    "\n",
    "**Pré-requisitos:**\n",
    "- Python 3.9+\n",
    "- Biblioteca `openai` instalada\n",
    "- Arquivo `.env` com `OPENAI_API_KEY` configurada\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "\n",
    "A API de Chat Completions da OpenAI permite criar conversas com modelos de linguagem como GPT-3.5-turbo e GPT-4. Esta é a base para todas as interações com modelos de texto da OpenAI.\n",
    "\n",
    "### Conceitos Fundamentais\n",
    "\n",
    "**Roles (Papéis):**\n",
    "- `system`: Define o contexto e comportamento do assistente\n",
    "- `user`: Mensagens do usuário final\n",
    "- `assistant`: Respostas anteriores do modelo (para manter contexto)\n",
    "\n",
    "**Modelos Disponíveis:**\n",
    "- `gpt-3.5-turbo`: Rápido e econômico, ideal para a maioria dos casos\n",
    "- `gpt-4`: Mais poderoso, melhor para tarefas complexas\n",
    "- `gpt-4-turbo`: Versão otimizada do GPT-4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cliente OpenAI configurado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Configuração inicial\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# Carregar variáveis de ambiente do arquivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Inicializar cliente OpenAI\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv('OPENAI_API_KEY')\n",
    ")\n",
    "\n",
    "print(\"Cliente OpenAI configurado com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo 1: Conversa Simples\n",
    "\n",
    "O exemplo mais básico: uma pergunta e uma resposta, sem contexto adicional.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resposta do modelo:\n",
      "Python é uma linguagem de programação de alto nível, interpretada, de tipagem dinâmica e multiplataforma. Foi criada por Guido van Rossum e lançada pela primeira vez em 1991. É uma linguagem muito popular devido à sua simplicidade de leitura e escrita, facilitando o desenvolvimento de aplicações em diversas áreas, como web, ciência de dados, inteligência artificial, automação, entre outras. Python é conhecida por sua filosofia de legibilidade e por sua vasta biblioteca padrão, que oferece uma ampla variedade de funcionalidades prontas para uso. Além disso, é uma linguagem de código aberto e tem uma grande comunidade de desenvolvedores ativos.\n"
     ]
    }
   ],
   "source": [
    "# Exemplo básico: pergunta simples\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"O que é Python?\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Resposta do modelo:\")\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo 2: Usando Role \"system\"\n",
    "\n",
    "O role `system` permite definir o contexto e comportamento do assistente. Isso é essencial para criar agentes especializados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resposta do assistente especializado:\n",
      "List comprehension é uma forma concisa de criar listas em Python. Com essa técnica, é possível gerar uma lista a partir de outra lista, aplicando uma expressão a cada elemento, ao invés de usar um loop tradicional.\n",
      "\n",
      "Por exemplo, se quisermos criar uma lista com o quadrado dos números de 1 a 5, podemos fazer dessa forma utilizando list comprehension:\n",
      "\n",
      "```python\n",
      "quadrados = [x**2 for x in range(1, 6)]\n",
      "```\n",
      "\n",
      "Nesse exemplo, a expressão `x**2` é aplicada a cada elemento `x` da lista `range(1, 6)`, gerando uma nova lista com os quadrados dos números de 1 a 5.\n",
      "\n",
      "A sintaxe básica da list comprehension é `[expressão for item in lista]`, onde \"expressão\" é o valor a ser incluído na nova lista e \"item\" é cada elemento da lista original. Ess\n"
     ]
    }
   ],
   "source": [
    "# Exemplo com role \"system\" para contextualizar o assistente\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Você é um professor de programação especializado em Python. Explique conceitos de forma clara e didática.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explique o conceito de list comprehension de forma simples.\"\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=200,  # Limita o tamanho da resposta\n",
    "    temperature=0.7  # Controla criatividade (0.0 = determinístico, 2.0 = muito criativo)\n",
    ")\n",
    "\n",
    "print(\"Resposta do assistente especializado:\")\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo 3: Conversa com Múltiplas Mensagens\n",
    "\n",
    "Para manter contexto em uma conversa, inclua as mensagens anteriores (tanto do usuário quanto do assistente).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resposta considerando o contexto:\n",
      "De acordo com estimativas recentes, a população de Brasília é de cerca de 3 milhões de habitantes.\n"
     ]
    }
   ],
   "source": [
    "# Conversa com histórico\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"Você é um assistente útil e prestativo.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Qual é a capital do Brasil?\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"A capital do Brasil é Brasília.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"E qual é a população aproximada?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(\"Resposta considerando o contexto:\")\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parâmetros Principais\n",
    "\n",
    "### `model`\n",
    "Escolha do modelo a ser usado:\n",
    "- `gpt-3.5-turbo`: Rápido e econômico (recomendado para a maioria dos casos)\n",
    "- `gpt-4`: Mais poderoso, melhor para tarefas complexas\n",
    "- `gpt-4-turbo`: Versão otimizada do GPT-4\n",
    "\n",
    "### `temperature` (0.0 a 2.0)\n",
    "Controla a aleatoriedade das respostas:\n",
    "- **0.0**: Determinístico, sempre a mesma resposta\n",
    "- **0.7**: Equilíbrio entre criatividade e precisão (padrão recomendado)\n",
    "- **1.5+**: Muito criativo, respostas variadas\n",
    "\n",
    "### `max_tokens`\n",
    "Limita o tamanho máximo da resposta:\n",
    "- Útil para controlar custos\n",
    "- Respostas são cortadas se excederem o limite\n",
    "- Padrão: determinado pelo modelo\n",
    "\n",
    "### `messages`\n",
    "Lista de mensagens que formam a conversa:\n",
    "- Cada mensagem tem `role` (system/user/assistant) e `content`\n",
    "- Ordem importa: o modelo processa sequencialmente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercícios Práticos\n",
    "\n",
    "### Exercício 1: Criar um Assistente de Culinária\n",
    "Crie um assistente especializado em receitas culinárias. Faça uma pergunta sobre como fazer um prato específico.\n",
    "\n",
    "**Dica:** Use `role: \"system\"` para definir o contexto do assistente.\n",
    "\n",
    "### Exercício 2: Comparar Modelos\n",
    "Teste a mesma pergunta com `gpt-3.5-turbo` e `gpt-4` e compare as respostas.\n",
    "\n",
    "### Exercício 3: Controlar Tamanho da Resposta\n",
    "Use `max_tokens` para limitar a resposta a 50 tokens e depois a 500 tokens. Observe a diferença.\n",
    "\n",
    "## Referências\n",
    "\n",
    "- [Documentação OpenAI - Chat Completions](https://platform.openai.com/docs/guides/text-generation)\n",
    "- [API Reference - Chat](https://platform.openai.com/docs/api-reference/chat)\n",
    "- [Modelos Disponíveis](https://platform.openai.com/docs/models)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (IAMASTER venv)",
   "language": "python",
   "name": "iamaster-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
