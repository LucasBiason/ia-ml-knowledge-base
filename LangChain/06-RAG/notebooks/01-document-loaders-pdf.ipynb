{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f844e932",
   "metadata": {},
   "source": [
    "# Tutorial 01: Document Loaders - Leitor de PDF Inteligente\n",
    "\n",
    "**Objetivos de Aprendizagem:**\n",
    "- Usar Document Loaders para carregar PDFs e outros documentos\n",
    "- Implementar Text Splitters para dividir documentos em chunks\n",
    "- Dominar estrat√©gias de chunking para otimizar processamento\n",
    "- Construir sistemas de an√°lise de documentos com IA\n",
    "- Criar sistemas de busca e filtros avan√ßados\n",
    "\n",
    "**Pr√©-requisitos:**\n",
    "- Tutorial 01-LLMs-Basicos: Introdu√ß√£o aos LLMs conclu√≠do\n",
    "- Tutorial 02-Prompts: ChatPromptTemplate (recomendado)\n",
    "- Compreens√£o b√°sica de Python e processamento de documentos\n",
    "\n",
    "---\n",
    "\n",
    "## Introdu√ß√£o\n",
    "\n",
    "Este tutorial demonstra como usar Document Loaders e Text Splitters do LangChain para processar documentos PDF. Aprenderemos a carregar documentos, dividi-los em chunks otimizados e analis√°-los com IA.\n",
    "\n",
    "### O que s√£o Document Loaders?\n",
    "\n",
    "**Document Loaders** s√£o componentes do LangChain que carregam documentos de diferentes fontes e os convertem em objetos `Document` padronizados.\n",
    "\n",
    "**Tipos de Loaders:**\n",
    "- PyPDFLoader: Carrega documentos PDF\n",
    "- DirectoryLoader: Carrega m√∫ltiplos arquivos\n",
    "- TextLoader: Carrega arquivos de texto\n",
    "- WebBaseLoader: Carrega conte√∫do de websites\n",
    "- YouTubeLoader: Carrega transcri√ß√µes do YouTube\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9b5292",
   "metadata": {},
   "source": [
    "### Conceitos-Chave\n",
    "\n",
    "**Document Loaders:**\n",
    "- PyPDFLoader: Carrega documentos PDF\n",
    "- DirectoryLoader: Carrega m√∫ltiplos arquivos\n",
    "- TextLoader: Carrega arquivos de texto\n",
    "- WebBaseLoader: Carrega conte√∫do de websites\n",
    "- YouTubeLoader: Carrega transcri√ß√µes do YouTube\n",
    "\n",
    "**Text Splitters:**\n",
    "- RecursiveCharacterTextSplitter: Divisor mais inteligente\n",
    "- CharacterTextSplitter: Divisor por caracteres\n",
    "- TokenTextSplitter: Divisor por tokens\n",
    "- Estrat√©gias de chunking otimizadas\n",
    "\n",
    "**Estrat√©gias de Chunking:**\n",
    "- chunk_size: Tamanho ideal dos chunks (1000-2000 caracteres)\n",
    "- chunk_overlap: Sobreposi√ß√£o entre chunks (200-400 caracteres)\n",
    "- separators: Caracteres para dividir o texto\n",
    "- length_function: Fun√ß√£o para calcular tamanho\n",
    "\n",
    "**An√°lise de Documentos com IA:**\n",
    "- Resumo autom√°tico: Gerar resumos de chunks\n",
    "- Extra√ß√£o de t√≥picos: Identificar temas principais\n",
    "- Sistema de Q&A: Responder perguntas sobre o documento\n",
    "- An√°lise de sentimento: Avaliar tom do conte√∫do\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81ee0f2",
   "metadata": {},
   "source": [
    "### Casos de Uso\n",
    "\n",
    "**Aplica√ß√µes Reais:**\n",
    "- Sistema de an√°lise de contratos e documentos legais\n",
    "- Plataforma de pesquisa acad√™mica e cient√≠fica\n",
    "- Sistema de suporte com base de conhecimento\n",
    "- An√°lise de relat√≥rios financeiros e empresariais\n",
    "- Sistema de busca em documentos corporativos\n",
    "\n",
    "**Habilidades Desenvolvidas:**\n",
    "- Processamento de documentos em larga escala\n",
    "- Otimiza√ß√£o de chunks para melhor performance\n",
    "- Integra√ß√£o com IA para an√°lise inteligente\n",
    "- Sistemas de busca e filtros avan√ßados\n",
    "- Exporta√ß√£o de dados em m√∫ltiplos formatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3ca6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura√ß√£o inicial\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Carregar vari√°veis de ambiente do arquivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Verificar se OPENAI_API_KEY est√° configurada\n",
    "if not os.getenv('OPENAI_API_KEY'):\n",
    "    print(\"‚ö†Ô∏è ATEN√á√ÉO: OPENAI_API_KEY n√£o encontrada no .env\")\n",
    "    print(\"   Configure a chave antes de continuar.\")\n",
    "else:\n",
    "    print(\"‚úÖ Vari√°veis de ambiente carregadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daebc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API Key carregada com sucesso!\n",
      "‚úÖ PDF encontrado: contrato.pdf\n"
     ]
    }
   ],
   "source": [
    "# Verificar se existe um PDF para teste\n",
    "pdf_path = Path(\"assets/contrato.pdf\")\n",
    "if pdf_path.exists():\n",
    "    print(f\"‚úÖ PDF encontrado: {pdf_path}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è PDF n√£o encontrado: {pdf_path}\")\n",
    "    print(\"   Certifique-se de ter um PDF na pasta assets/ para testar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd45c03",
   "metadata": {},
   "source": [
    "## Exemplo 1: Carregar PDF com PyPDFLoader\n",
    "\n",
    "Vamos carregar um documento PDF usando PyPDFLoader. O loader converte cada p√°gina do PDF em um objeto `Document` do LangChain.\n",
    "\n",
    "**Estrutura do Document:**\n",
    "- `page_content`: Texto extra√≠do da p√°gina\n",
    "- `metadata`: Metadados (source, page, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19b960b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "incorrect startxref pointer(1)\n",
      "parsing for Object Streams\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PDF carregado: 4 p√°ginas\n",
      "üìö Documentos carregados: 4\n"
     ]
    }
   ],
   "source": [
    "# Fun√ß√£o para carregar PDF\n",
    "def carregar_pdf(caminho_pdf):\n",
    "    \"\"\"\n",
    "    Carrega um PDF e retorna os documentos.\n",
    "    \n",
    "    Args:\n",
    "        caminho_pdf: Caminho para o arquivo PDF\n",
    "    \n",
    "    Returns:\n",
    "        Lista de objetos Document do LangChain\n",
    "    \"\"\"\n",
    "    try:\n",
    "        loader = PyPDFLoader(str(caminho_pdf))\n",
    "        documentos = loader.load()\n",
    "        print(f\"‚úÖ PDF carregado: {len(documentos)} p√°ginas\")\n",
    "        return documentos\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ö†Ô∏è Arquivo {caminho_pdf} n√£o encontrado\")\n",
    "        # Criar documento de exemplo\n",
    "        from langchain_core.documents import Document\n",
    "        documento_exemplo = Document(\n",
    "            page_content=\"Este √© um contrato de exemplo. Cont√©m cl√°usulas importantes sobre servi√ßos, pagamentos e responsabilidades. As partes concordam em cumprir todos os termos estabelecidos.\",\n",
    "            metadata={\"source\": \"exemplo\", \"page\": 1}\n",
    "        )\n",
    "        print(\"üìÑ Documento de exemplo criado\")\n",
    "        return [documento_exemplo]\n",
    "\n",
    "# Testar o loader (se PDF existir)\n",
    "if pdf_path.exists():\n",
    "    documentos = carregar_pdf(pdf_path)\n",
    "    print(f\"\\nPrimeira p√°gina (primeiros 200 caracteres):\")\n",
    "    print(documentos[0].page_content[:200] + \"...\")\n",
    "    print(f\"\\nMetadados da primeira p√°gina:\")\n",
    "    print(documentos[0].metadata)\n",
    "documentos = carregar_pdf(pdf_path)\n",
    "print(f\"üìö Documentos carregados: {len(documentos)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb85e74",
   "metadata": {},
   "source": [
    "## Por que dividir textos?\n",
    "\n",
    "### Problemas com textos longos:\n",
    "- Limite de tokens dos LLMs\n",
    "- Perda de contexto espec√≠fico\n",
    "- Dificuldade para an√°lise focada\n",
    "\n",
    "### Solu√ß√£o: Chunking inteligente\n",
    "- Divide em peda√ßos menores\n",
    "- Mant√©m sobreposi√ß√£o para contexto\n",
    "- Preserva estrutura sem√¢ntica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f82ec292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÇÔ∏è Text splitter configurado!\n",
      "   - Chunk size: 1000\n",
      "   - Chunk overlap: 200\n"
     ]
    }
   ],
   "source": [
    "# 5. CONFIGURAR TEXT SPLITTER\n",
    "def configurar_text_splitter(chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    üß† O que faz: Divide textos grandes em peda√ßos menores (chunks)\n",
    "    \n",
    "    Por que precisamos disso?\n",
    "    - LLMs t√™m limite de tokens\n",
    "    - Chunks menores = melhor compreens√£o\n",
    "    - Overlap = mant√©m contexto entre peda√ßos\n",
    "    \n",
    "    Par√¢metros:\n",
    "    - chunk_size: Tamanho m√°ximo de cada peda√ßo\n",
    "    - chunk_overlap: Sobreposi√ß√£o para manter contexto\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]  # Onde quebrar o texto\n",
    "    )\n",
    "    return text_splitter\n",
    "\n",
    "# Testar o text splitter\n",
    "text_splitter = configurar_text_splitter()\n",
    "print(\"‚úÇÔ∏è Text splitter configurado!\")\n",
    "print(f\"   - Chunk size: {text_splitter._chunk_size}\")\n",
    "print(f\"   - Chunk overlap: {text_splitter._chunk_overlap}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be9a15b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÔøΩÔøΩ Documento dividido em 7 chunks\n",
      "\n",
      "--- Chunk 1 ---\n",
      "Tamanho: 941 caracteres\n",
      "Conte√∫do: CONTRATO DE PRESTA√á√ÉO DE SERVI√áOS\n",
      " TECNOL√ìGICOS\n",
      "CONTRATANTE:\n",
      "TechCorp Solutions Ltda., pessoa jur√≠di...\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Tamanho: 723 caracteres\n",
      "Conte√∫do: e inscrita no CPF sob o n¬∫ 987.654.321-00.\n",
      "OBJETO DO CONTRATO:\n",
      "O presente contrato tem por objeto a ...\n",
      "\n",
      "--- Chunk 3 ---\n",
      "Tamanho: 940 caracteres\n",
      "Conte√∫do: PRAZO DE EXECU√á√ÉO:\n",
      "O prazo para execu√ß√£o total dos servi√ßos ser√° de 180 (cento e oitenta) dias corri...\n"
     ]
    }
   ],
   "source": [
    "# 6. DIVIDIR DOCUMENTOS EM CHUNKS\n",
    "def dividir_documentos(documentos, text_splitter):\n",
    "    \"\"\"\n",
    "    üìÑ O que faz: Pega os documentos e divide em peda√ßos menores\n",
    "    \n",
    "    Por que isso √© importante?\n",
    "    - Cada chunk pode ser processado separadamente\n",
    "    - Facilita a busca e recupera√ß√£o de informa√ß√µes\n",
    "    - Permite processar documentos muito grandes\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    for doc in documentos:\n",
    "        doc_chunks = text_splitter.split_documents([doc])\n",
    "        chunks.extend(doc_chunks)\n",
    "    \n",
    "    print(f\"ÔøΩÔøΩ Documento dividido em {len(chunks)} chunks\")\n",
    "    for i, chunk in enumerate(chunks[:3]):  # Mostrar primeiros 3 chunks\n",
    "        print(f\"\\n--- Chunk {i+1} ---\")\n",
    "        print(f\"Tamanho: {len(chunk.page_content)} caracteres\")\n",
    "        print(f\"Conte√∫do: {chunk.page_content[:100]}...\")\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Dividir documentos\n",
    "chunks = dividir_documentos(documentos, text_splitter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc2746c",
   "metadata": {},
   "source": [
    "## Estrat√©gia de An√°lise com IA\n",
    "\n",
    "### Abordagem em camadas:\n",
    "1. **Resumo de cada chunk**: Captura ideias principais\n",
    "2. **Identifica√ß√£o de t√≥picos**: Extrai temas e conceitos\n",
    "3. **Sistema de Q&A**: Permite perguntas espec√≠ficas\n",
    "\n",
    "### Vantagens:\n",
    "- An√°lise estruturada\n",
    "- Foco em informa√ß√µes relevantes\n",
    "- Facilita compreens√£o de documentos longos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "490fe2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÔøΩÔøΩ Sistema de an√°lise configurado!\n"
     ]
    }
   ],
   "source": [
    "# Configurar modelo de IA\n",
    "chat_model = ChatOpenAI(\n",
    "    temperature=0.1,  # Baixa temperatura para respostas consistentes\n",
    "    model_name=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "# Template para resumo\n",
    "template_resumo = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Voc√™ √© um especialista em an√°lise de documentos. Forne√ßa resumos concisos e objetivos.\"),\n",
    "    (\"human\", \"Resuma o seguinte texto em 2-3 frases:\\n\\n{texto}\")\n",
    "])\n",
    "\n",
    "# Template para an√°lise de t√≥picos\n",
    "template_topicos = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Identifique os 3 principais t√≥picos deste texto.\"),\n",
    "    (\"human\", \"Texto:\\n\\n{texto}\")\n",
    "])\n",
    "\n",
    "# Criar chains\n",
    "chain_resumo = template_resumo | chat_model | StrOutputParser()\n",
    "chain_topicos = template_topicos | chat_model | StrOutputParser()\n",
    "\n",
    "print(\"ÔøΩÔøΩ Sistema de an√°lise configurado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d355f5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ÔøΩÔøΩ Analisando Chunk 1...\n",
      "üìù Resumo: O contrato de presta√ß√£o de servi√ßos tecnol√≥gicos √© entre a TechCorp Solutions Ltda. e a Inova√ß√£o Digital Ltda., com o objetivo de desenvolvimento de servi√ßos tecnol√≥gicos. Os representantes legais de ambas as partes s√£o Jo√£o Silva Santos e Maria Oliveira Costa, respectivamente.\n",
      "ÔøΩÔøΩÔ∏è T√≥picos: 1. Contrato de presta√ß√£o de servi√ßos tecnol√≥gicos\n",
      "2. Partes envolvidas no contrato (Contratante e Contratada)\n",
      "3. Objeto do contrato (servi√ßos de desenvolvimento tecnol√≥gico)\n",
      "\n",
      "ÔøΩÔøΩ Analisando Chunk 2...\n",
      "üìù Resumo: O contrato tem como objetivo a presta√ß√£o de servi√ßos de desenvolvimento de software personalizado para gest√£o empresarial, utilizando tecnologias como Python, JavaScript, Django, React, PostgreSQL e AWS. O sistema incluir√° m√≥dulos para gest√£o de clientes, controle de estoque, faturamento, relat√≥rios gerenciais e integra√ß√£o com sistemas externos.\n",
      "ÔøΩÔøΩÔ∏è T√≥picos: 1. Objeto do contrato: presta√ß√£o de servi√ßos de desenvolvimento de software personalizado.\n",
      "2. Especifica√ß√µes t√©cnicas do sistema a ser desenvolvido, incluindo tecnologias e m√≥dulos espec√≠ficos.\n",
      "3. Detalhes sobre a empresa contratada, como nome, CNPJ e CPF.\n",
      "\n",
      "ÔøΩÔøΩ Analisando Chunk 3...\n",
      "üìù Resumo: O contrato prev√™ prazo de execu√ß√£o de 180 dias, podendo ser prorrogado por motivos t√©cnicos ou de for√ßa maior. O valor total dos servi√ßos √© de R$ 150.000, dividido em tr√™s parcelas, com reajuste anual pelo INPC, e a contratada √© respons√°vel pelo desenvolvimento do sistema, documenta√ß√£o, testes, treinamento e suporte t√©cnico.\n",
      "ÔøΩÔøΩÔ∏è T√≥picos: 1. Prazo de execu√ß√£o dos servi√ßos\n",
      "2. Valor e forma de pagamento\n",
      "3. Responsabilidades da contratada\n",
      "\n",
      "ÔøΩÔøΩ Analisando Chunk 4...\n",
      "üìù Resumo: O texto descreve as responsabilidades do fornecedor, que incluem fornecer documenta√ß√£o t√©cnica, realizar testes de qualidade, fornecer treinamento e suporte t√©cnico, manter sigilo e garantir a legalidade do software. J√° as responsabilidades da contratante envolvem fornecer informa√ß√µes, designar um representante t√©cnico, realizar testes de aceita√ß√£o, efetuar pagamentos, fornecer acesso a sistemas e participar de reuni√µes de acompanhamento. A confidencialidade tamb√©m √© mencionada como parte do acordo.\n",
      "ÔøΩÔøΩÔ∏è T√≥picos: 1. Responsabilidades da empresa contratada na presta√ß√£o de servi√ßos de desenvolvimento de software.\n",
      "2. Responsabilidades da empresa contratante no processo de desenvolvimento de software.\n",
      "3. Confidencialidade no contexto do contrato de presta√ß√£o de servi√ßos de desenvolvimento de software.\n",
      "\n",
      "ÔøΩÔøΩ Analisando Chunk 5...\n",
      "üìù Resumo: O contrato estabelece a confidencialidade das informa√ß√µes trocadas, com vig√™ncia por 5 anos ap√≥s o t√©rmino. A propriedade intelectual do projeto pertence √† Contratante, exceto por bibliotecas gen√©ricas da Contratada, e a rescis√£o pode ocorrer com aviso pr√©vio de 30 dias e pagamento de servi√ßos j√° prestados em caso de rescis√£o pela Contratante.\n",
      "ÔøΩÔøΩÔ∏è T√≥picos: 1. Confidencialidade de informa√ß√µes trocadas durante a execu√ß√£o do contrato\n",
      "2. Propriedade intelectual relacionada ao projeto desenvolvido\n",
      "3. Rescis√£o do contrato e suas condi√ß√µes\n",
      "\n",
      "ÔøΩÔøΩ Analisando Chunk 6...\n",
      "üìù Resumo: O texto estabelece que em caso de rescis√£o do contrato pela Contratada devido a descumprimento da Contratante, esta dever√° pagar multa de 20% do valor total. O foro para resolver quaisquer d√∫vidas ou lit√≠gios √© a Comarca de S√£o Paulo - SP, com as partes concordando e assinando o contrato em duas vias, na presen√ßa de testemunhas.\n",
      "ÔøΩÔøΩÔ∏è T√≥picos: 1. Cl√°usulas contratuais sobre rescis√£o e multa\n",
      "2. Foro para dirimir d√∫vidas ou lit√≠gios\n",
      "3. Assinatura do contrato pelas partes\n",
      "\n",
      "ÔøΩÔøΩ Analisando Chunk 7...\n",
      "üìù Resumo: O documento √© uma ata de reuni√£o ou assinatura de contrato, com a presen√ßa de Jo√£o Silva Santos e Maria Oliveira Costa como Diretor Executivo e Diretora Comercial, respectivamente. As testemunhas presentes s√£o Carlos Eduardo Lima, Ana Paula Rodrigues, Roberto Almeida Silva e Fernanda Costa Santos, com seus respectivos CPFs, datado de 15 de mar√ßo de 2024 em S√£o Paulo.\n",
      "ÔøΩÔøΩÔ∏è T√≥picos: 1. Assinaturas de testemunhas em um documento.\n",
      "2. Identifica√ß√£o dos indiv√≠duos presentes no documento.\n",
      "3. Local e data da assinatura do documento.\n"
     ]
    }
   ],
   "source": [
    "def analisar_chunks(chunks):\n",
    "    \"\"\"Analisa cada chunk com IA\"\"\"\n",
    "    resultados = []\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"\\nÔøΩÔøΩ Analisando Chunk {i+1}...\")\n",
    "        \n",
    "        # Resumo\n",
    "        resumo = chain_resumo.invoke({\"texto\": chunk.page_content})\n",
    "        print(f\"üìù Resumo: {resumo}\")\n",
    "        \n",
    "        # T√≥picos\n",
    "        topicos = chain_topicos.invoke({\"texto\": chunk.page_content})\n",
    "        print(f\"ÔøΩÔøΩÔ∏è T√≥picos: {topicos}\")\n",
    "        \n",
    "        resultados.append({\n",
    "            \"chunk_id\": i+1,\n",
    "            \"resumo\": resumo,\n",
    "            \"topicos\": topicos,\n",
    "            \"tamanho\": len(chunk.page_content)\n",
    "        })\n",
    "    \n",
    "    return resultados\n",
    "\n",
    "# Executar an√°lise\n",
    "resultados_analise = analisar_chunks(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64725751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì Testando sistema de perguntas e respostas:\n",
      "\n",
      "‚ùì Pergunta: Quais s√£o os principais t√≥picos deste documento?\n",
      "üí° Resposta: Os principais t√≥picos deste documento s√£o:\n",
      "\n",
      "1. Identifica√ß√£o das partes envolvidas (Contratante e Contratada).\n",
      "2. Objeto do contrato: presta√ß√£o de servi√ßos de desenvolvimento de software personalizado.\n",
      "3. Especifica√ß√µes t√©cnicas do sistema a ser desenvolvido.\n",
      "4. Prazo de execu√ß√£o dos servi√ßos.\n",
      "5. Valor e forma de pagamento.\n",
      "6. Responsabilidades da Contratada.\n",
      "7. Responsabilidades da Contratante.\n",
      "8. Confidencialidade das informa√ß√µes trocadas durante a execu√ß√£o do contrato.\n",
      "9. Propriedade intelectual dos materiais desenvolvidos.\n",
      "10. Rescis√£o do contrato.\n",
      "11. Foro para resolu√ß√£o de d√∫vidas ou lit√≠gios.\n",
      "12. Assinatura das partes e testemunhas.\n",
      "\n",
      "‚ùì Pergunta: H√° alguma cl√°usula importante mencionada?\n",
      "üí° Resposta: Sim, h√° v√°rias cl√°usulas importantes mencionadas no contrato de presta√ß√£o de servi√ßos tecnol√≥gicos, tais como:\n",
      "\n",
      "1. Objeto do contrato: Desenvolvimento de software personalizado para gest√£o empresarial.\n",
      "2. Especifica√ß√µes t√©cnicas: Tecnologias a serem utilizadas no desenvolvimento do sistema.\n",
      "3. Prazo de execu√ß√£o: 180 dias corridos, podendo ser prorrogado mediante acordo.\n",
      "4. Valor e forma de pagamento: Parcelamento do valor total dos servi√ßos e reajuste anual.\n",
      "5. Responsabilidades da contratada: Compromissos relacionados ao desenvolvimento, testes, suporte t√©cnico, entre outros.\n",
      "6. Responsabilidades da contratante: Compromissos relacionados ao fornecimento de informa√ß√µes, testes de aceita√ß√£o, pagamentos, entre outros.\n",
      "7. Confidencialidade: Obriga√ß√£o de manter informa√ß√µes confidenciais durante e ap√≥s o contrato.\n",
      "8. Propriedade intelectual: Defini√ß√£o da propriedade dos materiais desenvolvidos.\n",
      "9. Rescis√£o: Condi√ß√µes para rescis√£o do contrato por ambas as partes.\n",
      "10. Foro: Escolha do foro para dirimir d√∫vidas ou lit√≠gios.\n",
      "\n",
      "Essas cl√°usulas s√£o fundamentais para estabelecer os termos e condi√ß√µes do contrato entre as partes envolvidas.\n",
      "\n",
      "‚ùì Pergunta: Qual √© o objetivo geral deste documento?\n",
      "üí° Resposta: O objetivo geral deste documento √© formalizar um contrato de presta√ß√£o de servi√ßos tecnol√≥gicos entre a empresa TechCorp Solutions Ltda. (Contratante) e a empresa Inova√ß√£o Digital Ltda. (Contratada), estabelecendo as condi√ß√µes, responsabilidades, prazos, forma de pagamento, confidencialidade, propriedade intelectual, rescis√£o e foro para dirimir poss√≠veis lit√≠gios entre as partes.\n"
     ]
    }
   ],
   "source": [
    "# Template para Q&A\n",
    "template_qa = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Voc√™ √© um assistente especialista em documentos. Responda baseado apenas no contexto fornecido.\"),\n",
    "    (\"human\", \"Contexto:\\n{contexto}\\n\\nPergunta: {pergunta}\")\n",
    "])\n",
    "\n",
    "# Chain para Q&A\n",
    "chain_qa = template_qa | chat_model | StrOutputParser()\n",
    "\n",
    "def responder_pergunta(pergunta, chunks):\n",
    "    \"\"\"Responde perguntas baseado no conte√∫do dos chunks\"\"\"\n",
    "    # Concatenar conte√∫do relevante\n",
    "    contexto = \"\\n\\n\".join([chunk.page_content for chunk in chunks])\n",
    "    \n",
    "    # Gerar resposta\n",
    "    resposta = chain_qa.invoke({\n",
    "        \"contexto\": contexto,\n",
    "        \"pergunta\": pergunta\n",
    "    })\n",
    "    \n",
    "    return resposta\n",
    "\n",
    "# Testar sistema de Q&A\n",
    "perguntas_teste = [\n",
    "    \"Quais s√£o os principais t√≥picos deste documento?\",\n",
    "    \"H√° alguma cl√°usula importante mencionada?\",\n",
    "    \"Qual √© o objetivo geral deste documento?\"\n",
    "]\n",
    "\n",
    "print(\"‚ùì Testando sistema de perguntas e respostas:\")\n",
    "for pergunta in perguntas_teste:\n",
    "    print(f\"\\n‚ùì Pergunta: {pergunta}\")\n",
    "    resposta = responder_pergunta(pergunta, chunks)\n",
    "    print(f\"üí° Resposta: {resposta}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ba19f5",
   "metadata": {},
   "source": [
    "## üéØ Desafios para Praticar\n",
    "\n",
    "### Desafio 1: Diferentes Tipos de PDF\n",
    "- Teste com PDFs de diferentes tamanhos\n",
    "- Compare resultados com contratos, relat√≥rios, artigos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c9e484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Testando: chunk_size=500, chunk_overlap=50\n",
      "ÔøΩÔøΩ Documento dividido em 13 chunks\n",
      "\n",
      "--- Chunk 1 ---\n",
      "Tamanho: 451 caracteres\n",
      "Conte√∫do: CONTRATO DE PRESTA√á√ÉO DE SERVI√áOS\n",
      " TECNOL√ìGICOS\n",
      "CONTRATANTE:\n",
      "TechCorp Solutions Ltda., pessoa jur√≠di...\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Tamanho: 420 caracteres\n",
      "Conte√∫do: CONTRATADA:\n",
      "Inova√ß√£o Digital Ltda., pessoa jur√≠dica de direito privado, inscrita no CNPJ sob o n¬∫\n",
      "98...\n",
      "\n",
      "--- Chunk 3 ---\n",
      "Tamanho: 453 caracteres\n",
      "Conte√∫do: OBJETO DO CONTRATO:\n",
      "O presente contrato tem por objeto a presta√ß√£o de servi√ßos de desenvolvimento de...\n",
      "   üìä N√∫mero de chunks: 13\n",
      "   üìù Resumo: O contrato de presta√ß√£o de servi√ßos tecnol√≥gicos entre TechCorp Solutions Ltda. e Inova√ß√£o Digital Ltda. tem como objeto o desenvolvimento de um sistema de gest√£o empresarial, com prazo de execu√ß√£o de 180 dias e valor total de R$ 150.000,00, dividido em tr√™s parcelas. Ambas as partes se comprometem a manter a confidencialidade das informa√ß√µes trocadas, com a propriedade intelectual do projeto pertencendo exclusivamente √† Contratante, e estabelecem cl√°usulas de rescis√£o e foro para resolu√ß√£o de lit√≠gios.\n",
      "\n",
      "üîß Testando: chunk_size=1000, chunk_overlap=200\n",
      "ÔøΩÔøΩ Documento dividido em 7 chunks\n",
      "\n",
      "--- Chunk 1 ---\n",
      "Tamanho: 941 caracteres\n",
      "Conte√∫do: CONTRATO DE PRESTA√á√ÉO DE SERVI√áOS\n",
      " TECNOL√ìGICOS\n",
      "CONTRATANTE:\n",
      "TechCorp Solutions Ltda., pessoa jur√≠di...\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Tamanho: 723 caracteres\n",
      "Conte√∫do: e inscrita no CPF sob o n¬∫ 987.654.321-00.\n",
      "OBJETO DO CONTRATO:\n",
      "O presente contrato tem por objeto a ...\n",
      "\n",
      "--- Chunk 3 ---\n",
      "Tamanho: 940 caracteres\n",
      "Conte√∫do: PRAZO DE EXECU√á√ÉO:\n",
      "O prazo para execu√ß√£o total dos servi√ßos ser√° de 180 (cento e oitenta) dias corri...\n",
      "   üìä N√∫mero de chunks: 7\n",
      "   üìù Resumo: O contrato de presta√ß√£o de servi√ßos tecnol√≥gicos entre TechCorp Solutions Ltda. e Inova√ß√£o Digital Ltda. tem como objeto o desenvolvimento de software personalizado de gest√£o empresarial, com prazo de execu√ß√£o de 180 dias e valor total de R$ 150.000,00, dividido em parcelas. Ambas as partes se comprometem com responsabilidades espec√≠ficas, confidencialidade e propriedade intelectual, com possibilidade de rescis√£o mediante notifica√ß√£o pr√©via de 30 dias e foro na Comarca de S√£o Paulo - SP para eventuais lit√≠gios.\n",
      "\n",
      "üîß Testando: chunk_size=2000, chunk_overlap=400\n",
      "ÔøΩÔøΩ Documento dividido em 4 chunks\n",
      "\n",
      "--- Chunk 1 ---\n",
      "Tamanho: 1521 caracteres\n",
      "Conte√∫do: CONTRATO DE PRESTA√á√ÉO DE SERVI√áOS\n",
      " TECNOL√ìGICOS\n",
      "CONTRATANTE:\n",
      "TechCorp Solutions Ltda., pessoa jur√≠di...\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Tamanho: 1520 caracteres\n",
      "Conte√∫do: PRAZO DE EXECU√á√ÉO:\n",
      "O prazo para execu√ß√£o total dos servi√ßos ser√° de 180 (cento e oitenta) dias corri...\n",
      "\n",
      "--- Chunk 3 ---\n",
      "Tamanho: 1414 caracteres\n",
      "Conte√∫do: As partes se comprometem a manter estritamente confidenciais todas as informa√ß√µes\n",
      "t√©cnicas, comercia...\n",
      "   üìä N√∫mero de chunks: 4\n",
      "   üìù Resumo: O contrato estabelece a presta√ß√£o de servi√ßos de desenvolvimento de software personalizado pela empresa Inova√ß√£o Digital Ltda. para a TechCorp Solutions Ltda., com prazo de execu√ß√£o de 180 dias e valor total de R$ 150.000,00, dividido em parcelas. As responsabilidades das partes incluem o desenvolvimento conforme especifica√ß√µes, fornecimento de documenta√ß√£o t√©cnica, testes de qualidade, pagamento nos prazos acordados, entre outros, com cl√°usulas de confidencialidade, propriedade intelectual e rescis√£o estabelecidas.\n",
      "\n",
      "üîß Testando: chunk_size=500, chunk_overlap=200\n",
      "ÔøΩÔøΩ Documento dividido em 16 chunks\n",
      "\n",
      "--- Chunk 1 ---\n",
      "Tamanho: 451 caracteres\n",
      "Conte√∫do: CONTRATO DE PRESTA√á√ÉO DE SERVI√áOS\n",
      " TECNOL√ìGICOS\n",
      "CONTRATANTE:\n",
      "TechCorp Solutions Ltda., pessoa jur√≠di...\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Tamanho: 479 caracteres\n",
      "Conte√∫do: brasileiro, casado, portador da C√©dula de Identidade RG n¬∫ 12.345.678-9 SSP/SP e\n",
      "inscrito no CPF sob...\n",
      "\n",
      "--- Chunk 3 ---\n",
      "Tamanho: 484 caracteres\n",
      "Conte√∫do: Janeiro - RJ, CEP 20000-000, representada por sua Diretora Comercial, Maria Oliveira\n",
      "Costa, brasilei...\n",
      "   üìä N√∫mero de chunks: 16\n",
      "   üìù Resumo: O contrato de presta√ß√£o de servi√ßos tecnol√≥gicos entre TechCorp Solutions Ltda. e Inova√ß√£o Digital Ltda. tem como objeto o desenvolvimento de software personalizado de gest√£o empresarial, com prazo de execu√ß√£o de 180 dias e valor total de R$ 150.000,00, dividido em parcelas. Ambas as partes se comprometem com responsabilidades espec√≠ficas, confidencialidade e propriedade intelectual, podendo rescindir o contrato mediante notifica√ß√£o escrita com anteced√™ncia m√≠nima de 30 dias, com foro na Comarca de S√£o Paulo - SP.\n"
     ]
    }
   ],
   "source": [
    "def comparar_configuracoes_chunks(documentos):\n",
    "    \"\"\"Compara diferentes configura√ß√µes de chunking\"\"\"\n",
    "    configs = [\n",
    "        (500, 50),   # Chunks pequenos, pouca sobreposi√ß√£o\n",
    "        (1000, 200), # Configura√ß√£o padr√£o\n",
    "        (2000, 400), # Chunks grandes, muita sobreposi√ß√£o\n",
    "        (500, 200),  # Chunks pequenos, muita sobreposi√ß√£o\n",
    "    ]\n",
    "    \n",
    "    resultados = []\n",
    "    \n",
    "    for chunk_size, chunk_overlap in configs:\n",
    "        print(f\"\\nüîß Testando: chunk_size={chunk_size}, chunk_overlap={chunk_overlap}\")\n",
    "        \n",
    "        # Configurar splitter\n",
    "        splitter = configurar_text_splitter(chunk_size, chunk_overlap)\n",
    "        \n",
    "        # Dividir documentos\n",
    "        chunks = dividir_documentos(documentos, splitter)\n",
    "        \n",
    "        # An√°lise r√°pida\n",
    "        resumo_geral = chain_resumo.invoke({\n",
    "            \"texto\": \"\\n\".join([chunk.page_content for chunk in chunks])\n",
    "        })\n",
    "        \n",
    "        resultados.append({\n",
    "            \"config\": (chunk_size, chunk_overlap),\n",
    "            \"num_chunks\": len(chunks),\n",
    "            \"resumo\": resumo_geral\n",
    "        })\n",
    "        \n",
    "        print(f\"   üìä N√∫mero de chunks: {len(chunks)}\")\n",
    "        print(f\"   üìù Resumo: {resumo_geral}\")\n",
    "    \n",
    "    return resultados\n",
    "\n",
    "# Executar compara√ß√£o\n",
    "resultados_comparacao = comparar_configuracoes_chunks(documentos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1585081",
   "metadata": {},
   "source": [
    "\n",
    "### Desafio 2: Otimiza√ß√£o de Chunks\n",
    "- Teste diferentes valores de chunk_size e chunk_overlap\n",
    "- Encontre a configura√ß√£o ideal para seu tipo de documento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fd2707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ JSON salvo: analise_pdf_20250904_181253.json\n",
      "üíæ CSV salvo: analise_pdf_chunks_20250904_181253.csv\n",
      "üíæ Markdown salvo: analise_pdf_20250904_181253.md\n",
      "‚úÖ Exporta√ß√£o conclu√≠da em 3 formatos!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "def exportar_resultados(resultados_analise, resultados_comparacao, filename_prefix=\"analise_pdf\"):\n",
    "    \"\"\"Exporta resultados em diferentes formatos\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Preparar dados para exporta√ß√£o\n",
    "    dados_export = {\n",
    "        \"timestamp\": timestamp,\n",
    "        \"analise_chunks\": resultados_analise,\n",
    "        \"comparacao_configs\": resultados_comparacao\n",
    "    }\n",
    "    \n",
    "    # 1. JSON\n",
    "    json_filename = f\"{filename_prefix}_{timestamp}.json\"\n",
    "    with open(json_filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(dados_export, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"üíæ JSON salvo: {json_filename}\")\n",
    "    \n",
    "    # 2. CSV para an√°lise de chunks\n",
    "    csv_filename = f\"{filename_prefix}_chunks_{timestamp}.csv\"\n",
    "    with open(csv_filename, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=['chunk_id', 'resumo', 'topicos', 'tamanho'])\n",
    "        writer.writeheader()\n",
    "        for resultado in resultados_analise:\n",
    "            writer.writerow(resultado)\n",
    "    print(f\"üíæ CSV salvo: {csv_filename}\")\n",
    "    \n",
    "    # 3. Markdown\n",
    "    md_filename = f\"{filename_prefix}_{timestamp}.md\"\n",
    "    with open(md_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"# An√°lise de PDF - {timestamp}\\n\\n\")\n",
    "        \n",
    "        f.write(\"## An√°lise por Chunks\\n\\n\")\n",
    "        for resultado in resultados_analise:\n",
    "            f.write(f\"### Chunk {resultado['chunk_id']}\\n\")\n",
    "            f.write(f\"- **Resumo**: {resultado['resumo']}\\n\")\n",
    "            f.write(f\"- **T√≥picos**: {resultado['topicos']}\\n\")\n",
    "            f.write(f\"- **Tamanho**: {resultado['tamanho']} caracteres\\n\\n\")\n",
    "        \n",
    "        f.write(\"## Compara√ß√£o de Configura√ß√µes\\n\\n\")\n",
    "        for resultado in resultados_comparacao:\n",
    "            chunk_size, chunk_overlap = resultado['config']\n",
    "            f.write(f\"### Configura√ß√£o: {chunk_size}/{chunk_overlap}\\n\")\n",
    "            f.write(f\"- **Chunks**: {resultado['num_chunks']}\\n\")\n",
    "            f.write(f\"- **Resumo**: {resultado['resumo']}\\n\\n\")\n",
    "    \n",
    "    print(f\"üíæ Markdown salvo: {md_filename}\")\n",
    "    print(\"‚úÖ Exporta√ß√£o conclu√≠da em 3 formatos!\")\n",
    "\n",
    "# Executar exporta√ß√£o\n",
    "exportar_resultados(resultados_analise, resultados_comparacao)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06dc7b6",
   "metadata": {},
   "source": [
    "\n",
    "### Desafio 3: Sistema de Busca\n",
    "- Implemente busca por palavras-chave nos chunks\n",
    "- Crie filtros por metadados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6452126e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "incorrect startxref pointer(1)\n",
      "parsing for Object Streams\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç TESTANDO SISTEMA DE BUSCA\n",
      "==================================================\n",
      "‚úÖ PDF carregado: 4 p√°ginas\n",
      "ÔøΩÔøΩ Documento dividido em 7 chunks\n",
      "\n",
      "--- Chunk 1 ---\n",
      "Tamanho: 941 caracteres\n",
      "Conte√∫do: CONTRATO DE PRESTA√á√ÉO DE SERVI√áOS\n",
      " TECNOL√ìGICOS\n",
      "CONTRATANTE:\n",
      "TechCorp Solutions Ltda., pessoa jur√≠di...\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Tamanho: 723 caracteres\n",
      "Conte√∫do: e inscrita no CPF sob o n¬∫ 987.654.321-00.\n",
      "OBJETO DO CONTRATO:\n",
      "O presente contrato tem por objeto a ...\n",
      "\n",
      "--- Chunk 3 ---\n",
      "Tamanho: 940 caracteres\n",
      "Conte√∫do: PRAZO DE EXECU√á√ÉO:\n",
      "O prazo para execu√ß√£o total dos servi√ßos ser√° de 180 (cento e oitenta) dias corri...\n",
      "‚úÖ √çndice criado com 7 chunks\n",
      "üîç Encontrados 0 chunks com 'intelig√™ncia'\n",
      "üìö Encontrados 0 chunks sobre 'machine learning'\n",
      "üéØ Encontrados 2 chunks com 'dados' e tamanho >= 500\n",
      "\n",
      "‚úÖ Sistema de busca implementado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Desafio 3: Sistema de Busca\n",
    "def buscar_palavras_chave(chunks, palavra_chave, metadados_filtro=None):\n",
    "    \"\"\"\n",
    "    Busca por palavras-chave nos chunks com filtros opcionais\n",
    "    \n",
    "    Args:\n",
    "        chunks: Lista de chunks para buscar\n",
    "        palavra_chave: Palavra-chave para buscar\n",
    "        metadados_filtro: Dicion√°rio com filtros de metadados (ex: {'source': 'arquivo.pdf'})\n",
    "    \n",
    "    Returns:\n",
    "        Lista de chunks que cont√™m a palavra-chave\n",
    "    \"\"\"\n",
    "    resultados = []\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        # Verifica se a palavra-chave est√° no conte√∫do\n",
    "        if palavra_chave.lower() in chunk.page_content.lower():\n",
    "            # Aplica filtros de metadados se fornecidos\n",
    "            if metadados_filtro:\n",
    "                chunk_metadados = chunk.metadata\n",
    "                filtro_ok = True\n",
    "                \n",
    "                for chave, valor in metadados_filtro.items():\n",
    "                    if chave not in chunk_metadados or chunk_metadados[chave] != valor:\n",
    "                        filtro_ok = False\n",
    "                        break\n",
    "                \n",
    "                if filtro_ok:\n",
    "                    resultados.append(chunk)\n",
    "            else:\n",
    "                resultados.append(chunk)\n",
    "    \n",
    "    return resultados\n",
    "\n",
    "def buscar_por_topicos(chunks, topico):\n",
    "    \"\"\"\n",
    "    Busca chunks relacionados a um t√≥pico espec√≠fico\n",
    "    \n",
    "    Args:\n",
    "        chunks: Lista de chunks para buscar\n",
    "        topico: T√≥pico para buscar\n",
    "    \n",
    "    Returns:\n",
    "        Lista de chunks relacionados ao t√≥pico\n",
    "    \"\"\"\n",
    "    output_parser = StrOutputParser()\n",
    "    \n",
    "    # Cria um prompt para identificar se o chunk √© relacionado ao t√≥pico\n",
    "    prompt_topicos = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Voc√™ √© um especialista em an√°lise de conte√∫do. Determine se o texto fornecido est√° relacionado ao t√≥pico especificado. Responda apenas 'SIM' ou 'N√ÉO'.\"),\n",
    "        (\"human\", \"T√≥pico: {topico}\\n\\nTexto: {texto}\")\n",
    "    ])\n",
    "    \n",
    "    chain_topicos = prompt_topicos | chat_model | output_parser\n",
    "    resultados = []\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        resposta = chain_topicos.invoke({\"topico\": topico, \"texto\": chunk.page_content})\n",
    "        if resposta.upper() == \"SIM\":\n",
    "            resultados.append(chunk)\n",
    "    \n",
    "    return resultados\n",
    "\n",
    "def criar_indice_busca(chunks):\n",
    "    \"\"\"\n",
    "    Cria um √≠ndice de busca para facilitar consultas\n",
    "    \n",
    "    Args:\n",
    "        chunks: Lista de chunks para indexar\n",
    "    \n",
    "    Returns:\n",
    "        Dicion√°rio com √≠ndice de busca\n",
    "    \"\"\"\n",
    "    indice = {\n",
    "        'por_palavra': {},\n",
    "        'por_tamanho': {},\n",
    "        'por_fonte': {},\n",
    "        'por_pagina': {}\n",
    "    }\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        # √çndice por palavra-chave\n",
    "        palavras = chunk.page_content.lower().split()\n",
    "        for palavra in palavras:\n",
    "            if palavra not in indice['por_palavra']:\n",
    "                indice['por_palavra'][palavra] = []\n",
    "            indice['por_palavra'][palavra].append(i)\n",
    "        \n",
    "        # √çndice por tamanho\n",
    "        tamanho = len(chunk.page_content)\n",
    "        if tamanho not in indice['por_tamanho']:\n",
    "            indice['por_tamanho'][tamanho] = []\n",
    "        indice['por_tamanho'][tamanho].append(i)\n",
    "        \n",
    "        # √çndice por fonte\n",
    "        fonte = chunk.metadata.get('source', 'desconhecida')\n",
    "        if fonte not in indice['por_fonte']:\n",
    "            indice['por_fonte'][fonte] = []\n",
    "        indice['por_fonte'][fonte].append(i)\n",
    "        \n",
    "        # √çndice por p√°gina\n",
    "        pagina = chunk.metadata.get('page', 0)\n",
    "        if pagina not in indice['por_pagina']:\n",
    "            indice['por_pagina'][pagina] = []\n",
    "        indice['por_pagina'][pagina].append(i)\n",
    "    \n",
    "    return indice\n",
    "\n",
    "def buscar_com_indice(indice, chunks, palavra_chave=None, tamanho_min=None, fonte=None, pagina=None):\n",
    "    \"\"\"\n",
    "    Busca usando o √≠ndice criado\n",
    "    \n",
    "    Args:\n",
    "        indice: √çndice de busca\n",
    "        chunks: Lista de chunks\n",
    "        palavra_chave: Palavra-chave para buscar\n",
    "        tamanho_min: Tamanho m√≠nimo do chunk\n",
    "        fonte: Fonte espec√≠fica\n",
    "        pagina: P√°gina espec√≠fica\n",
    "    \n",
    "    Returns:\n",
    "        Lista de chunks que atendem aos crit√©rios\n",
    "    \"\"\"\n",
    "    indices_encontrados = set(range(len(chunks)))\n",
    "    \n",
    "    # Filtro por palavra-chave\n",
    "    if palavra_chave:\n",
    "        palavra_lower = palavra_chave.lower()\n",
    "        if palavra_lower in indice['por_palavra']:\n",
    "            indices_encontrados = indices_encontrados.intersection(set(indice['por_palavra'][palavra_lower]))\n",
    "        else:\n",
    "            return []  # Palavra n√£o encontrada\n",
    "    \n",
    "    # Filtro por tamanho m√≠nimo\n",
    "    if tamanho_min:\n",
    "        indices_tamanho = []\n",
    "        for tamanho, indices in indice['por_tamanho'].items():\n",
    "            if tamanho >= tamanho_min:\n",
    "                indices_tamanho.extend(indices)\n",
    "        indices_encontrados = indices_encontrados.intersection(set(indices_tamanho))\n",
    "    \n",
    "    # Filtro por fonte\n",
    "    if fonte:\n",
    "        if fonte in indice['por_fonte']:\n",
    "            indices_encontrados = indices_encontrados.intersection(set(indice['por_fonte'][fonte]))\n",
    "        else:\n",
    "            return []  # Fonte n√£o encontrada\n",
    "    \n",
    "    # Filtro por p√°gina\n",
    "    if pagina is not None:\n",
    "        if pagina in indice['por_pagina']:\n",
    "            indices_encontrados = indices_encontrados.intersection(set(indice['por_pagina'][pagina]))\n",
    "        else:\n",
    "            return []  # P√°gina n√£o encontrada\n",
    "    \n",
    "    return [chunks[i] for i in indices_encontrados]\n",
    "\n",
    "# Teste do sistema de busca\n",
    "print(\"üîç TESTANDO SISTEMA DE BUSCA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Carrega o PDF de exemplo\n",
    "documento = carregar_pdf(\"contrato.pdf\")\n",
    "text_splitter = configurar_text_splitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = dividir_documentos(documento, text_splitter)\n",
    "\n",
    "# Cria √≠ndice de busca\n",
    "indice = criar_indice_busca(chunks)\n",
    "print(f\"‚úÖ √çndice criado com {len(chunks)} chunks\")\n",
    "\n",
    "# Busca por palavra-chave\n",
    "resultados_palavra = buscar_palavras_chave(chunks, \"intelig√™ncia\")\n",
    "print(f\"üîç Encontrados {len(resultados_palavra)} chunks com 'intelig√™ncia'\")\n",
    "\n",
    "# Busca por t√≥pico\n",
    "resultados_topico = buscar_por_topicos(chunks, \"machine learning\")\n",
    "print(f\"üìö Encontrados {len(resultados_topico)} chunks sobre 'machine learning'\")\n",
    "\n",
    "# Busca com filtros\n",
    "resultados_filtrados = buscar_com_indice(indice, chunks, palavra_chave=\"dados\", tamanho_min=500)\n",
    "print(f\"üéØ Encontrados {len(resultados_filtrados)} chunks com 'dados' e tamanho >= 500\")\n",
    "\n",
    "print(\"\\n‚úÖ Sistema de busca implementado com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f03e319",
   "metadata": {},
   "source": [
    "\n",
    "### Desafio 4: Exporta√ß√£o de Resultados\n",
    "- Salve an√°lises em diferentes formatos (JSON, CSV, Markdown)\n",
    "- Crie relat√≥rios estruturados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbe976cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä TESTANDO EXPORTA√á√ÉO DE RESULTADOS\n",
      "==================================================\n",
      "‚úÖ An√°lise exportada para teste_analise.json\n",
      "‚úÖ An√°lise exportada para teste_analise.csv\n",
      "‚úÖ An√°lise exportada para teste_analise.md\n",
      "‚úÖ An√°lise exportada para teste_relatorio_20250904_190726.json\n",
      "‚úÖ An√°lise exportada para teste_relatorio_20250904_190726.csv\n",
      "‚úÖ An√°lise exportada para teste_relatorio_20250904_190726.md\n",
      "‚úÖ Relat√≥rio executivo exportado para teste_relatorio_executivo_20250904_190726.md\n",
      "‚úÖ Relat√≥rio completo exportado com prefixo: teste_relatorio_20250904_190726\n",
      "\n",
      "‚úÖ Sistema de exporta√ß√£o implementado com sucesso!\n",
      "üìÅ Verifique os arquivos gerados no diret√≥rio atual\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "def exportar_analise_json(resultados_analise, filename=\"analise_pdf.json\"):\n",
    "    \"\"\"\n",
    "    Exporta resultados da an√°lise em formato JSON\n",
    "    \n",
    "    Args:\n",
    "        resultados_analise: Dicion√°rio com resultados da an√°lise\n",
    "        filename: Nome do arquivo para salvar\n",
    "    \"\"\"\n",
    "    # Prepara dados para exporta√ß√£o\n",
    "    dados_export = {\n",
    "        \"metadata\": {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"total_chunks\": len(resultados_analise),\n",
    "            \"versao\": \"1.0\"\n",
    "        },\n",
    "        \"resultados\": []\n",
    "    }\n",
    "    \n",
    "    for i, resultado in enumerate(resultados_analise):\n",
    "        dados_export[\"resultados\"].append({\n",
    "            \"chunk_id\": i,\n",
    "            \"resumo\": resultado[\"resumo\"],\n",
    "            \"topicos\": resultado[\"topicos\"],\n",
    "            \"tamanho\": resultado[\"tamanho\"],\n",
    "            \"pagina\": resultado[\"pagina\"],\n",
    "            \"fonte\": resultado[\"fonte\"]\n",
    "        })\n",
    "    \n",
    "    # Salva arquivo JSON\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(dados_export, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"‚úÖ An√°lise exportada para {filename}\")\n",
    "\n",
    "def exportar_analise_csv(resultados_analise, filename=\"analise_pdf.csv\"):\n",
    "    \"\"\"\n",
    "    Exporta resultados da an√°lise em formato CSV\n",
    "    \n",
    "    Args:\n",
    "        resultados_analise: Dicion√°rio com resultados da an√°lise\n",
    "        filename: Nome do arquivo para salvar\n",
    "    \"\"\"\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        # Cabe√ßalho\n",
    "        writer.writerow(['Chunk ID', 'Resumo', 'T√≥picos', 'Tamanho', 'P√°gina', 'Fonte'])\n",
    "        \n",
    "        # Dados\n",
    "        for i, resultado in enumerate(resultados_analise):\n",
    "            writer.writerow([\n",
    "                i,\n",
    "                resultado[\"resumo\"],\n",
    "                \", \".join(resultado[\"topicos\"]),\n",
    "                resultado[\"tamanho\"],\n",
    "                resultado[\"pagina\"],\n",
    "                resultado[\"fonte\"]\n",
    "            ])\n",
    "    \n",
    "    print(f\"‚úÖ An√°lise exportada para {filename}\")\n",
    "\n",
    "def exportar_analise_markdown(resultados_analise, filename=\"analise_pdf.md\"):\n",
    "    \"\"\"\n",
    "    Exporta resultados da an√°lise em formato Markdown\n",
    "    \n",
    "    Args:\n",
    "        resultados_analise: Dicion√°rio com resultados da an√°lise\n",
    "        filename: Nome do arquivo para salvar\n",
    "    \"\"\"\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"# An√°lise de PDF com IA\\n\\n\")\n",
    "        f.write(f\"**Data:** {datetime.now().strftime('%d/%m/%Y %H:%M')}\\n\")\n",
    "        f.write(f\"**Total de Chunks:** {len(resultados_analise)}\\n\\n\")\n",
    "        \n",
    "        f.write(\"## Resumo Executivo\\n\\n\")\n",
    "        f.write(\"Este documento cont√©m a an√°lise autom√°tica de um PDF utilizando t√©cnicas de IA.\\n\\n\")\n",
    "        \n",
    "        f.write(\"## Resultados por Chunk\\n\\n\")\n",
    "        \n",
    "        for i, resultado in enumerate(resultados_analise):\n",
    "            f.write(f\"### Chunk {i+1}\\n\\n\")\n",
    "            f.write(f\"**P√°gina:** {resultado['pagina']}\\n\")\n",
    "            f.write(f\"**Fonte:** {resultado['fonte']}\\n\")\n",
    "            f.write(f\"**Tamanho:** {resultado['tamanho']} caracteres\\n\\n\")\n",
    "            \n",
    "            f.write(\"**Resumo:**\\n\")\n",
    "            f.write(f\"{resultado['resumo']}\\n\\n\")\n",
    "            \n",
    "            f.write(\"**T√≥picos Identificados:**\\n\")\n",
    "            for topico in resultado['topicos']:\n",
    "                f.write(f\"- {topico}\\n\")\n",
    "            f.write(\"\\n---\\n\\n\")\n",
    "    \n",
    "    print(f\"‚úÖ An√°lise exportada para {filename}\")\n",
    "\n",
    "def exportar_relatorio_completo(resultados_analise, resultados_busca=None, filename_prefix=\"relatorio_pdf\"):\n",
    "    \"\"\"\n",
    "    Exporta relat√≥rio completo em m√∫ltiplos formatos\n",
    "    \n",
    "    Args:\n",
    "        resultados_analise: Resultados da an√°lise\n",
    "        resultados_busca: Resultados de buscas (opcional)\n",
    "        filename_prefix: Prefixo para os arquivos\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Exporta em diferentes formatos\n",
    "    exportar_analise_json(resultados_analise, f\"{filename_prefix}_{timestamp}.json\")\n",
    "    exportar_analise_csv(resultados_analise, f\"{filename_prefix}_{timestamp}.csv\")\n",
    "    exportar_analise_markdown(resultados_analise, f\"{filename_prefix}_{timestamp}.md\")\n",
    "    \n",
    "    # Cria relat√≥rio executivo\n",
    "    relatorio_executivo = f\"{filename_prefix}_executivo_{timestamp}.md\"\n",
    "    with open(relatorio_executivo, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"# Relat√≥rio Executivo - An√°lise de PDF\\n\\n\")\n",
    "        f.write(f\"**Data:** {datetime.now().strftime('%d/%m/%Y %H:%M')}\\n\\n\")\n",
    "        \n",
    "        f.write(\"## Estat√≠sticas Gerais\\n\\n\")\n",
    "        f.write(f\"- **Total de Chunks:** {len(resultados_analise)}\\n\")\n",
    "        f.write(f\"- **P√°ginas Analisadas:** {len(set(r['pagina'] for r in resultados_analise))}\\n\")\n",
    "        f.write(f\"- **Tamanho M√©dio dos Chunks:** {sum(r['tamanho'] for r in resultados_analise) // len(resultados_analise)} caracteres\\n\\n\")\n",
    "        \n",
    "        f.write(\"## T√≥picos Mais Frequentes\\n\\n\")\n",
    "        todos_topicos = []\n",
    "        for resultado in resultados_analise:\n",
    "            todos_topicos.extend(resultado['topicos'])\n",
    "        \n",
    "        from collections import Counter\n",
    "        topicos_frequentes = Counter(todos_topicos).most_common(10)\n",
    "        \n",
    "        for topico, frequencia in topicos_frequentes:\n",
    "            f.write(f\"- **{topico}:** {frequencia} ocorr√™ncias\\n\")\n",
    "        \n",
    "        f.write(\"\\n## Recomenda√ß√µes\\n\\n\")\n",
    "        f.write(\"1. **Foco em T√≥picos Principais:** Concentre-se nos t√≥picos mais frequentes\\n\")\n",
    "        f.write(\"2. **An√°lise Detalhada:** Use os chunks maiores para an√°lise aprofundada\\n\")\n",
    "        f.write(\"3. **Busca Estrat√©gica:** Utilize o sistema de busca para encontrar informa√ß√µes espec√≠ficas\\n\")\n",
    "        f.write(\"4. **Monitoramento:** Acompanhe a evolu√ß√£o dos t√≥picos ao longo do documento\\n\")\n",
    "    \n",
    "    print(f\"‚úÖ Relat√≥rio executivo exportado para {relatorio_executivo}\")\n",
    "    print(f\"‚úÖ Relat√≥rio completo exportado com prefixo: {filename_prefix}_{timestamp}\")\n",
    "\n",
    "def exportar_resultados_busca(resultados_busca, filename=\"resultados_busca.json\"):\n",
    "    \"\"\"\n",
    "    Exporta resultados de busca em formato JSON\n",
    "    \n",
    "    Args:\n",
    "        resultados_busca: Dicion√°rio com resultados de busca\n",
    "        filename: Nome do arquivo para salvar\n",
    "    \"\"\"\n",
    "    dados_export = {\n",
    "        \"metadata\": {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"total_resultados\": len(resultados_busca),\n",
    "            \"versao\": \"1.0\"\n",
    "        },\n",
    "        \"resultados\": []\n",
    "    }\n",
    "    \n",
    "    for resultado in resultados_busca:\n",
    "        dados_export[\"resultados\"].append({\n",
    "            \"conteudo\": resultado.page_content,\n",
    "            \"metadados\": resultado.metadata,\n",
    "            \"tamanho\": len(resultado.page_content)\n",
    "        })\n",
    "    \n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(dados_export, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"‚úÖ Resultados de busca exportados para {filename}\")\n",
    "\n",
    "# Teste da exporta√ß√£o\n",
    "print(\"üìä TESTANDO EXPORTA√á√ÉO DE RESULTADOS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Simula resultados de an√°lise para teste\n",
    "resultados_teste = [\n",
    "    {\n",
    "        \"resumo\": \"Introdu√ß√£o aos conceitos de IA\",\n",
    "        \"topicos\": [\"intelig√™ncia artificial\", \"machine learning\", \"introdu√ß√£o\"],\n",
    "        \"tamanho\": 500,\n",
    "        \"pagina\": 1,\n",
    "        \"fonte\": \"exemplo.pdf\"\n",
    "    },\n",
    "    {\n",
    "        \"resumo\": \"Aplica√ß√µes pr√°ticas de ML\",\n",
    "        \"topicos\": [\"aplica√ß√µes\", \"pr√°tica\", \"machine learning\"],\n",
    "        \"tamanho\": 750,\n",
    "        \"pagina\": 2,\n",
    "        \"fonte\": \"exemplo.pdf\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Exporta em diferentes formatos\n",
    "exportar_analise_json(resultados_teste, \"teste_analise.json\")\n",
    "exportar_analise_csv(resultados_teste, \"teste_analise.csv\")\n",
    "exportar_analise_markdown(resultados_teste, \"teste_analise.md\")\n",
    "exportar_relatorio_completo(resultados_teste, filename_prefix=\"teste_relatorio\")\n",
    "\n",
    "print(\"\\n‚úÖ Sistema de exporta√ß√£o implementado com sucesso!\")\n",
    "print(\"üìÅ Verifique os arquivos gerados no diret√≥rio atual\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
